\section{Architecture overview}\label{section:architecture}
    \begin{figure}
        \centering
        \begin{tikzpicture}

            % \draw[help lines] (0,0) grid (8.5,16);

            % Output
            \node[architecture_node_fullwidth,fill=waterblue,architecture_no_fill] (output) at (1,16) {Output};

            % Classificator
            % \node[architecture_box,minimum width=7.2cm,minimum height=4.7cm] (classification_architecture) at (.9,14.6) {};
            \node[architecture_node_fullwidth,fill=purple,architecture_no_fill] (classification) at (1,14.5) {Classification};
                    % CNN
                \matrix[architecture_node_nofill,minimum width=\onethird,minimum height=2cm,inner sep=0mm,fill=blue,architecture_no_fill] (cnn) at (1,13.5) {
                    \node {CNN}; & \node (cnn_local) {CNN}; & \node {CNN}; \\
                };
                \draw[black] (cnn_local.north east)--(cnn_local.south east);
                \draw[black] (cnn_local.north west)--(cnn_local.south west);

                    % INPUT
                \matrix[architecture_node_nofill,minimum width=\onethird,minimum height=1cm,inner sep=0mm,row sep=-0.51cm,fill=lightblue,architecture_no_fill] (cnn_features) at (1,11.5) {
                    \node (cnn_shape_feature) {Shape Feature}; & \node (cnn_local_feature) {Local Feature}; & \node (cnn_global_feature) {Global Feature}; \\
                    \node (cnn_shape_feature_color) {b/w}; & \node (cnn_local_feature_color) {Gray levels}; & \node (cnn_global_feature_color) {Gray levels}; \\
                };
                \draw[black] (cnn_local_feature.north east)--(cnn_local_feature_color.south east);
                \draw[black] (cnn_local_feature.north west)--(cnn_local_feature_color.south west);
            
            \draw[->] ($(classification.north) + (0,.05)$) -- ($(output.south) + (0,-0.05)$);

            % INPUT PREPROCESSING
                % Enhanced image
                \node[architecture_node_fullwidth,minimum height=4.7cm,fill=lightyellow,architecture_no_fill] (enhanced_image_box) at (1,9.5) {};
                \node[architecture_node_fullwidth,minimum height=1cm,anchor=south west,draw=none] (enhanced_image_label) at (1,4.8) {Enhanced Image};
                % \node[architecture_box,minimum width=7.2cm,minimum height=4.9cm] (preprocessing_architecture) at (.9,9.6) {};

                % Padding
                \matrix[architecture_node_nofill,minimum width=\onethird,minimum height=1cm,inner sep=0mm,row sep=-0.51cm,fill=lightred,architecture_no_fill] (cnn) at (1,9.5) {
                    \node (padding1) {Padding \&}; & \node (padding2) {Padding \&};\\
                    \node {Centering}; & \node (centering2) {Centering};\\
                };
                \draw[black] (padding2.north west)--(centering2.south west);

                % Segmentation & Bounding box
                \matrix[architecture_node_nofill,minimum width=\onethird - .6mm,minimum height=1cm,inner sep=.5mm,nodes={draw=black},fill=lightorange,architecture_no_fill,nodes={fill=orange,architecture_no_fill}] (segmentation_bounding_box) at (1,8) {
                    \node {Segmentation}; & \node {Bounding Box};\\
                };

                % Border detection & Region proposals
                \node[architecture_node_nofill,minimum width=2*\onethird,minimum height=1cm,fill=yellow,architecture_no_fill] (border) at (1,6.88) {Border detection};
            
            \draw[->] ($(segmentation_bounding_box.west) + (0.03,0)$) -- ($(segmentation_bounding_box.west) + (-0.5,0)$) -- ($(output.west) + (-0.5,0)$) -- ($(output.west) + (-0.05,0)$);
            \draw[->] ($(padding1.north) + (0,.05)$) -- ($(cnn_shape_feature_color.south) + (0,-0.05)$);
            \draw[->] ($(padding2.north) + (0,.05)$) -- ($(cnn_local_feature_color.south) + (0,-0.05)$);
            \draw[->] ($(enhanced_image_box.north) + (2.3cm,.05)$) -- ($(cnn_global_feature_color.south) + (0,-0.05)$);

            % Raw image
            \node[architecture_node_fullwidth,fill=green,architecture_no_fill] (rawim) at (1,4.3) {Raw Image};
            \draw[->] ($(rawim.north) + (0,.05)$) -- ($(enhanced_image_box.south) + (0,-0.05)$);

        \end{tikzpicture}
        \caption{Proposed defect detection system architecture}\label{fig:architecture}
    \end{figure}

    \par{
        The defect detection system architecture proposed in this paper is described in \emph{Figure \ref{fig:architecture}}.
    }

    \par{
        Steel surfaces pictures of $1600\times 256$ pixels are taken at the input of the process. Since they may be taken under different light exposure conditions, some preprocessing is made to enhance the quality of the image, e.g. histogram equalization or linear scaling. Moreover, the images considered have three equal colours levels, therefore they are converted into gray levels, to save space. This first step is further described in \emph{Section \ref{section:image_preprocessing}}.
    }
    \par{
        The aim of the architecture proposed in this paper is both to detect pixels representing steel imperfections and to classify those regions. Therefore, image segmentation is either obtained as an output of the system or it is needed in some step during the process. The latter situation can be achieved through a brute-force multi-scale sliding window, but to improve performances without reducing accuracy a particular implementation of a Region based CNN (R-CNN) \cite{ieee:7410526,ieee:7532516} is proposed in \emph{Section \ref{section:mc-cnn}}. This R-CNN uses a MC-CNN to combine and to consider separately interesting regions, which are called proposals and which are described in \emph{Section \ref{section:region_proposals}}.
    }
    \par{
        This reduces the computational cost of the system, compared with a naive sliding window.
    }
    \par{
        Moreover, both local and global information are combined to improve classification accuracy. This approach avoids the complexity of combining different scale information and handling windows with different classes of defects. A further description of this approach is provided in \emph{Section \ref{section:mc-cnn}}, whereas in \emph{Section \ref{section:further-work}} a challenger architecture is described, to compare the results of the proposed system with.
    }
    \par{
        One column of the MC-CNN is concerned with global information, and it is fed with the full enchanced image. Conceptually, this CNN learns to evaluate the probability of presence of the different types of defects in the whole surface picture. The other two columns consider local information instead. This local information is obtained from a further processing step, described in \emph{Section \ref{section:region_proposals}}. First, a contour detection algorithm (\emph{Section \ref{subsection:contour_detection}}) is used to spot proposals. Second, image segmentation (\emph{Section \ref{subsection:segmentation}}) is done, to feed the MC-CNN only with some interesting regions. This segmentation results in a black and white (b/w) map describing the shape of the plausible defects. One column of the MC-CNN is fed with this map, therefore it learns to classify regions only observing their border. The other column is fed with the portion of original image enveloped in the bounding box (\emph{Section \ref{subsection:bounding_box}}) of the map, hence, it is trained to consider luminance levels inside, outside and on the border of the considered proposals.
    }
    \par{
        Since defects may have different dimensions, the local information are centered in a $1600\times 256$ pixels black image.
    }
    \par{
        All the MC-CNN columns end with a softmax layer. However, they have different output size, as described in \emph{Section \ref{section:mc-cnn}}. Their results are then combined in order to properly classify the local regions.
    }
    \par{
        Finally, if the classification outcome labels the region as defective, segmentation coordinates are kept. When all the proposals of the considered image are processed, defective pixels of the same class are encoded together with RLE algorithm. If the surface is flawless, all this encodings are empty.
    }