\section{Results}\label{section:results}
    Review the article, make some considerations on results
    Observe that this architecture is dealing with different sixze image, interesting.....!!!

    \subsection{Detector}
        \par{
		    ***DESCRIVERE ACCURATEZZA***
		    \begin{equation*}
		    \mathcal{A}\left(X, Y\right) = \frac{\lvert X \cap Y \rvert}{\lvert Y \rvert}
		    \end{equation*}
		}
        \begin{figure}
    	\centering
    	\includegraphics[width=\linewidth]{graphics/results/segmentation_opt_class1}
    	\caption{Bayesian optimization of class 1 detector}\label{fig:bayesopt-class1}
    \end{figure}
    \begin{figure}
    	\centering
    	\includegraphics[width=\linewidth]{graphics/results/segmentation_opt_class1}
    	\caption{Bayesian optimization of class 2 detector}\label{fig:bayesopt-class2}
    \end{figure}
    \begin{figure}
    	\centering
    	\includegraphics[width=\linewidth]{graphics/results/segmentation_opt_class3}
    	\caption{Bayesian optimization of class 3 detector}\label{fig:bayesopt-class3}
    \end{figure}
    \begin{figure}
    	\centering
    	\includegraphics[width=\linewidth]{graphics/results/segmentation_opt_class4}
    	\caption{Bayesian optimization of class 4 detector}\label{fig:bayesopt-class4}
    \end{figure}
    \begin{table}
		\centering
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			\textbf{Parameters} & \textbf{Class 1} & \textbf{Class 2} & \textbf{Class 3} & \textbf{Class 4}\\ \hline
			$N$ & 3 & 4 & 5 & 4 \\ \hline
			$U$ & 15 & 7 & 5 & 15 \\ \hline
			$\lambda$ & 3.9199 & 2.3621 & 4.9810 & 3.5076 \\ \hline
			$s$ & 2.1161 & 1.5552 & 1.5559 & 1.4307 \\ \hline
			$T_{low}$ & 59 & 77 & 60 & 59 \\ \hline
			$T_{high}$ & 113 & 212 & 104 & 179 \\ \hline
			$\alpha$ & 7 & 8 & 6 & 6 \\ \hline
			$T_{hole}$ & 9593 & 6460 & 7179 & 9986 \\ \hline
			$T_{region}$ & 510 & 942 & 727 & 1134 \\ \hline
		\end{tabular}
		\vspace{0.25cm}
		\caption{Optimal parameters obtained for each class detector with Bayesian optimization.}\label{table:bayesopt-params}
	\end{table}
	\begin{figure}
		\centering
		\includegraphics[width=\linewidth]{graphics/results/acc-segmentation-class1}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/acc-segmentation-class2}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/acc-segmentation-class3}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/acc-segmentation-class4}
		\vskip .05cm
		\caption{INSERIRE}\label{fig:segmentation-test}
	\end{figure}
	\begin{table}
		\centering
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			\textbf{Detector} & \textbf{Eq.} & \textbf{MinMax} & \textbf{Batch size} & \textbf{Loss} & \textbf{Accuracy}\\ \hline
			1 & yes & no & 5 & 4 & 4 \\ \hline
			2 & no & yes & 5 & 15 & 4\\ \hline
			3 & yes & yes & 4.9810 & 3.5076 & 4\\ \hline
		\end{tabular}
		\vspace{0.25cm}
		\caption{Optimal parameters obtained for each class detector with Bayesian optimization.}\label{table:bayesopt-params}
	\end{table}
	\begin{figure}
		\centering
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class1}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class1-edges}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class1-segmentation}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class1-bounding-box}
		\vskip .05cm
		\caption{INSERIRE}\label{fig:detector-results-1}
	\end{figure}
	\begin{figure}
		\centering
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class2}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class2-edges}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class2-segmentation}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class2-bounding-box}
		\vskip .05cm
		\caption{INSERIRE}\label{fig:detector-results-2}
	\end{figure}
	\begin{figure}
		\centering
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class3}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class3-edges}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class3-segmentation}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class3-bounding-box}
		\vskip .05cm
		\caption{INSERIRE}\label{fig:detector-results-3}
	\end{figure}
	\begin{figure}
		\centering
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class4}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class4-edges}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class4-segmentation}
		\vskip .05cm
		\includegraphics[width=\linewidth]{graphics/results/detector-result-class4-bounding-box}
		\vskip .05cm
		\caption{INSERIRE}\label{fig:detector-results-4}
	\end{figure}

    \subsection{Classificator}
    \par{

    }
    \begin{figure}
        \centering
        % \includegraphics[width=.8\linewidth]{graphics/results/mc-cnn-local-confusion}
        \caption{Local column confusion matrix on ideal input.}\label{fig:local-confusion}
    \end{figure}
    \begin{table}
        \centering
        \normalsize
        \caption{Local column comparisons}\label{table:results:local-comparisons}
    \end{table}
    \par{
        ** COMPARISONS with / without equalization local column **
    }
    \par{
        ** COMPARISONS crop / spreader local column **
    }
    \subsection{Architecture implementation}
    \par{
        The whole system implementation can be found in the \href{https://github.com/antonioterpin/wavelet_ml}{\texttt{GitHub}} repository \cite{antonioterpin:github}.
    }

\section{Further work}\label{section:further-work}
    \par{
        This work can be further developed in many ways.
    }
    \subsection{Proposed architecture improvement}
    \par{
        Firstly, it would be interest to implement and train the shape column, preeptively discarding misleading data, and the global column and measure their contribution. The structure of the shape column may be identical to the local column, described in \emph{Section \ref{section:local-column}}.
    }
    \par{
        Regarding the local column, some padding could be considered around defective regions, to fed the CNN also with some more pixels outside the border.
    }
    \par{
        Secondly, the final classifier should be implemented to realize the end-to-end system and evaluate its performance.
    }
    \par{
        Thirdly, as announced in \emph{Section \ref{section:local-column}}, both the local and the shape column could be fed with a cropped image. One could attempt to preemptively discard these outliers and try to optimize the other samples with a smaller input and, hence, more traditional classificators.
    }
    \begin{table*}
        \centering
        \normalsize
        \begin{tabular}{|c|c|c|c|c|c|}
            \hline
            \textbf{Cropping size} & \textbf{Class No.1 outliers} & \textbf{Class No.2 outliers}& \textbf{Class No.3 outliers} & \textbf{Class No.4 outliers} & \textbf{Overall outliers}\\\hline
            $800\times 800$ & $0\%$ & $0\%$ & $1.47\%$ & $1.06\%$ & $0.88\%$\\
            $512\times 512$ & $0\%$ & $0\%$ & $2.94\%$ & $3.99\%$ & $2.11\%$\\
            $256\times 256$ & $0\%$ & $0\%$ & $6.61\%$ & $17.57\%$& $6.42\%$\\
            \hline
        \end{tabular}
        \vspace{0.5cm}
        \caption{Cropping examples.}\label{table:cropping}
    \end{table*}
    \par{
        Some examples of interesting cropping size are shown in \emph{Table \ref{table:cropping}}.
    }
    \subsection{Challenger}
    \par{
        Some comparisons with a challenger architecture are needed to evaluate the effectiveness of the proposed system.
    }
    \par{
        As an example, a well-known \emph{sliding window} classificator could be used.
    }
    \subsubsection{Sliding window architecture}
        \par{
            The idea behind this architecture is to crop the input image at different locations (eventually all the ones possible, as in this paper) and use a classifier to assign to the pixels of the considered region an array of confidences.
        }
        \begin{figure}
            \centering
            \begin{tikzpicture}
                % Image
                \node[rectangle, draw, minimum width=3cm, minimum height=3cm] (image) at (0,0) {Image};
                % Window
                \node[rectangle, draw=red, minimum width=.8cm, minimum height=.8cm] (window) at ($(image) + (.3,.9)$) {};
                % Sliding window
                \draw[->, draw=red] ($(window) + (.2,0)$) -- ($(window) + (1,0)$);
                \draw[->, draw=red] ($(window) + (0,-.2)$) -- ($(window) + (0,-.7)$);
                % Classifier
                \node[rounded rectangle, draw, minimum width=2cm, minimum height=1cm] (classifier) at ($(image) + (2.5,0)$) {Classifier};
                \draw[->,draw=blue] ($(window) + (0,0)$) -- (classifier);
                % Confidence map
                \node[rectangle,draw,minimum width=3cm, minimum height=3cm] (confidence map) at ($(classifier) + (2.5,0)$) {Confidence map};
                \node[rectangle, draw=red, minimum width=.8cm, minimum height=.8cm] (confidence map window) at ($(confidence map) + (.3,.9)$) {};
                \draw[->, draw=red] ($(confidence map window) + (.2,0)$) -- ($(confidence map window) + (1,0)$);
                \draw[->, draw=red] ($(confidence map window) + (0,-.2)$) -- ($(confidence map window) + (0,-.7)$);
                \draw[->,draw=blue] (classifier) -- ($(confidence map window)$);
            \end{tikzpicture}
            \caption{Sliding window architecture}\label{fig:sliding-window}
        \end{figure}
        \par{
            This cropped regions may overlap. In those circumstances, an heuristic to combine different values of confidences is needed.
        }
        \par{
            In \emph{Figure \ref{fig:sliding-window}} the sketch of this architecture is shown. In the illustration the resulting map, called \emph{confidence map}, is associated to an array of confidences relative to the possible labels. 
        }
        \par{
            The \emph{confidence map} is then used along with some image segmentation tecnique to spot defective regions. In particular, a $n+1$ levels whatershed algorithm is proposed in \emph{Section \ref{section:challenger:image-segmentation}}.
        }
        \par{
            Since defects may have different dimensions, more refined tecniques could be used to improve the accuracy of the challenger. However, these are outside the scope of this work, and they are proposed as a further development in \emph{Section \ref{section:further-work}}. Moreover, the segmentation tecnique proposed in \emph{Section \ref{section:challenger:image-segmentation}} soothes this problem, since it combines local information from different areas to build the defective regions.
        }
    \subsubsection{Image segmentation}\label{section:challenger:image-segmentation}
        \par{
            The \emph{confidence map} is used to segmentate the image through a $n+1$ levels whatershed algorithm. However, since the defective regions are always disjunct, the problem can be reduced to a binary whatershed algorithm \cite{ieee:87344} considering all the defective classes as one, and distinguishing them only later. The $n+1$ levels whatershed algorithm is left as a further development in \emph{Section \ref{section:further-work}}.
        }
        \par{
            As a final remark about the challenger, it is patent that even this naive implementation is far more involved then the proposed architecture, and the reason lies on the image segmentation approach.
        }
    \par{
        Moreover, the challenger could be further refined. As an example, a multi-scale approach could be considered, since the challenger does not take into account the variability of defects dimensions. To solve this flaw, \emph{image pyramids} could be used.
    }
    \par{
        Finally, an interesting development would be to investigate further a segmentation with overlapping (adjacent) regions, when there are more classes then foreground/background only. Towards this multi-level segmentation, it would be interesting to consider a non-binary whatershed-based algorithm.
    }