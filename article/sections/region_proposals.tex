\section{Detector}\label{section:region_proposals}
    \par{
        The second stage of the proposed architecture is the \emph{detector} of region proposals, which are then fed into the \emph{classificator} for classification, which is described in \emph{Section} \ref{section:mc-cnn}.
    }
    \par{
        The whole system relies on the \emph{detector} to spot one or more region of interest (ROI), which are the plausible candidates to be defective regions.
    }
    \par{
        To extract them, firstly an edge detector is used (\emph{Section \ref{subsection:contour_detection}}). Its output is a binary matrix describing the edges found. The alpha shape of this matrix is then used to segmentate ROIs (\emph{Section \ref{subsection:segmentation}}). Finally, the bounding box of the regions can be easily calculated (\emph{Section \ref{subsection:bounding_box}}).
    }
    \subsection{Edge detection}\label{subsection:contour_detection}
        \par{
            The first step towards segmentation consists of the detection of edges within the image. The usage of Kovesi algorithm (KA) \cite{mit:kovesiphase, googlescholar:kovesiphase} together with hysteretic edge follower \cite{Klette:2014:CCV:2584519}.
        }
        \par{
            KA is a \emph{phase congruency}-based edge detector. The main idea is that where the local frequency components of an image are in phase, there is an edge \cite{researchgate:morrone}. This concept is illustrated in \emph{Figure \ref{fig:phase-congruency}}.
        }
        \par{
            Some phase congruency metrics are based on Fourier analysis and on measuring the local energy \cite{researchgate:phase}, whereas KA exploits the log-Gabor wavelets. These are shown in \emph{Figure \ref{fig:gabor}}.
        }
    	\begin{figure}
    		\centering
    		\includegraphics[width=.9\linewidth]{graphics/architecture/phasecong}
    		\caption{Visualization of the phase congruency concept for a 1D signal. The sum (blue curve) of the frequency components (red and orange curves) gradually approaches a discontinuity where the components are in phase.}
    		\label{fig:phase-congruency}
    	\end{figure}
    	\begin{figure}
    		\centering
    		\includegraphics[width=\linewidth]{graphics/architecture/gabor}
    		\caption{Examples of log-Gabor wavelets with different directions and scales.}
    		\label{fig:gabor}
    	\end{figure}
		\par{
			Given a image and fixed a direction $u$, for each pixel $q$ a squared local window $W(q)$ is considered. It is an image crop centered in $q$. Then, $W(q)$ is convolved with the log-Gabor wavelets at different scales $n = 0 \dots N-1$, obtaining the complex number:
	    	\begin{equation*}
	    		z_{n} (q) = G_{n} * W(q) = r_{n} (q) e^{i \alpha_{n} (q)}.
	    	\end{equation*}
	    	Then, the phase congruency measure at $q$ is:
            \begin{equation*}
	            \mathcal{P} (q) = \frac{\max(0,\lvert \sum_{n} z_{n} (q) \rvert - T)}{\sum_{n} r_{n} (q) + \varepsilon},
            \end{equation*}
            where $T$ is a constant that soothes the effects of noise and $\varepsilon$ is a small value, used to avoid numerical problems concerning negligible values of $r_n$. 
        }
        \par{
            One of the advantages of this measure is that it is dimensionless. The concept behind this metric is illustrated in \emph{Figure \ref{fig:phase-congruency-metric}}.
        }
	    \begin{figure}
	    	\centering
	    	\includegraphics[width=\linewidth]{graphics/architecture/phasecong_metric}
	    	\caption{Phase congruency metric.}
	    	\label{fig:phase-congruency-metric}
	    \end{figure}
	    \par{
	    	The local window $W(q)$ size is $(2k+1)\times(2k+1)$, with $2k+1 \geq 3\lambda$.
		}
        \par{
        	$\mathcal{P}$ lies in the $[0,1]$ interval. However, as reported in \emph{Section \ref{section:results}}, the \emph{min-max normalization}
        	\begin{equation*}
        	\hat{\mathcal{P}}(q) = 255 \cdot \frac{\mathcal{P}(q)-\min_q\mathcal{P}(q)}{\max_q\mathcal{P}(q)-\min_q\mathcal{P}(q)}
        	\end{equation*}
        	 on KA output improves the performance of the detector stage.
        }
        \par{
        	KA is based on several parameters that need to be tuned to obtain an effective edge detector. In this paper, the \emph{number of scales} $N$, the \emph{number of orientations} $U$, the \emph{minimum wavelength} $\lambda$ and the \emph{scaling factor} $s$ of the wavelets are considered. Their tuning was performed through Bayesian optimization \cite{arXiv:2012arXiv1206.2944S,arXiv:2018arXiv180702811F, matlab:bayesian-opt}, as described in section \ref{subsection:segmentation}.
        }
        \par{
            It is not recommend to use directly the output of KA for image segmentation, since it is tipically susceptible to isolated edge-like patterns that arise in sparse locations within the image. Hence, a hysteretic edge follower was used to discard such patterns.
        }
        \par{
            Let $\mathcal{I}$ be the image, $\mathcal{Q} = \left\{q \in \mathcal{I} \colon \hat{\mathcal{P}}(q) > T_{high}\right\}$, $\Omega(q)$ the set of  pixels adjacent to $q$ and $\mathcal{E} = \empty$ the set of edge pixels.
        }
        \par{
            Then, the hysteretic edge follower calculates edge pixels as:
            \begin{enumerate}
    			\item $q_i \in \mathcal{Q};\; \mathcal{Q} = \mathcal{Q} \setminus \{q_i\};\;\mathcal{E} = \mathcal{E} \cup \{q_i\}$
    			\item $\forall q_j \in \Omega(q_i)$ if $\hat{\mathcal{P}}(q_j) > T_{low}$ then $\mathcal{E} = \mathcal{E} \cup \{q_j\}$ and repeat $(2)$ with $q_i = q_j$
    			\item if $\mathcal{Q} \neq \empty$ then repeat $(1)$
    		\end{enumerate}
        }
		\par{
			The final output is a binary matrix marking the positions of edge pixels. The hysteretic parameters \emph{low-threshold} $T_{low}$ and \emph{high-threshold} $T_{high}$ need to be properly tuned, in order to improve the effectiveness of edge detection, as illustrated in \emph{Figure \ref{fig:edge-detector-example}}. Therefore, they were free parameters during the Bayesian optimization, together with KA ones.
        }
    	\par{
    		The described techniques \texttt{MATLAB} implementation is freely available at \cite{kovesilibrary}.
    	}
    	\begin{figure} 		  
    		\includegraphics[width=\linewidth]{graphics/architecture/detector-ex}
    		\vskip .05cm
    		\includegraphics[width=\linewidth]{graphics/architecture/detector-ex-hysteresis-30-50}
    		\vskip .05cm \includegraphics[width=\linewidth]{graphics/architecture/detector-ex-hysteresis-60-100}
    		\vskip .05cm \includegraphics[width=\linewidth]{graphics/architecture/detector-ex-hysteresis-90-150}
    		\vskip .05cm
    		\caption{Output of the edge detector on a sample image using different thresholds $(T_{low},T_{high})$. Respectively, from top to bottom: $(30,50)$, $(60,100)$ and $(100,150)$. Standard parameters of the Kovesi algorithm has been used.}
    		\label{fig:edge-detector-example}
    	\end{figure}
    
    \subsection{Image Segmentation}\label{subsection:segmentation}
        \par{
            Given the plausible edges found by the previous step, image segmentation is performed banking on alpha shapes \cite{springer:10.1007/11907350_46}.
        }
        \par{
            The Delaunay triangulation $\mathcal{D}$ od a set of point $\mathcal{S}$ is the subset of all triangles $T = \left\{\left(a, b, c\right) \subset \mathcal{S}^3, a \neq b, b \neq c, a \neq c \right\}$ such that $t \in T, x \in \mathcal{S} \Rightarrow x \not\in \mathcal{C}\left(t\right)$, where $\mathcal{C}\left(t\right)$ is the circumcircle of $t$.
        }
        \par{
            The union of cells $c \in \mathcal{D}$ is called polytope of $\mathcal{D}$. 
            \begin{equation*}
                \mathcal{D}_\alpha = \left\{t \in T \colon r\left(\mathcal{C}\left(t\right)\right) < \alpha\right\},
            \end{equation*}
            where $r\left(\mathcal{C}\left(t\right)\right)$ is the radius of the circumcircle of $t$. The polytope of $\mathcal{D}_\alpha$ is called \emph{alpha-shape}.
        }
        \begin{figure}
            \centering
            \includegraphics[width=\linewidth]{graphics/architecture/detector-points}
            \includegraphics[width=\linewidth]{graphics/architecture/detector-a-shape}
            \includegraphics[width=\linewidth]{graphics/architecture/detector-a-shape-better-radius}
            \caption{Alpha shape with different alphas of a set of points.}\label{fig:example-alpha-shape}
        \end{figure}
        \begin{figure}
            \centering
            \includegraphics[width=\linewidth]{graphics/architecture/detector-convhull}
            \caption{Convex hull of a set of points.}\label{fig:example-convex-hull}
        \end{figure}
        \par{
            As an example, in \emph{Figure \ref{fig:example-alpha-shape}} are compared the alpha-shapes with different $\alpha$ values of a set of points. In \emph{Figure \ref{fig:example-convex-hull}} is shown the convex-hull of the same set of points. The choice of alpha shapes for the given task is clear.
        }
        \par{
            However, in order to obtain topologically correct image segmentation, three parameters need to be properly chosen \cite{springer:10.1007/11907350_46}. These are the \emph{alpha-radius} $\alpha$, the \emph{hole-thresholding} $T_{hole}$ and the \emph{region-thresholding} $T_{region}$ \cite{matlab:alpha-shape}.
        }
        \par{
            The first is the value of $\alpha$, the second is the maximum area of interior holes that is filled and the third is the largest area that is suppressed (ignored).
        }
        \par{
            Observe that the latter is useful to soothe the effects of noisy edge detections.
        }
        \par{
            However, tuning them manually is quixotic, hence they are choosen through Bayesian optimization.
        }
        \par{
            The segmentation step outputs a set of pixels, which can be compared with the ideal segmentation, i.e. only the pixels within some defective region.
        }
        \par{
            Therefore, the goodness of fit of the set of proposed pixels $\left(X\right)$ to the ideal pixels $\left(Y\right)$ can be measured as:
            \begin{equation*}
                \chi\left(X, Y\right) = \frac{2 \lvert X \cap Y \rvert}{\lvert X \rvert + \lvert Y \rvert}.
            \end{equation*}
        }
        \par{
            Hence, the loss function is:
            \begin{equation*}
                \mathcal{L}\left(X, Y\right) = 1 - \chi\left(X, Y\right).
            \end{equation*}
        }
	    \par{
		    DESCRIVERE ACCURATEZZA
		    \begin{equation*}
		    \mathcal{A}\left(X, Y\right) = \frac{\lvert X \cap Y \rvert}{\lvert Y \rvert}
		    \end{equation*}
		}
        \par{
            The acquisition function used is \emph{expected-improvement-plus} \cite{matlab:acquisition}.
        }
        \par{
            As a final consideration, using alpha shape lessen the detrimental effect of the noise in edge detection. Indeed, outliers are suppressed by the hole threshold and region threshold parameteres.
        }
        \par{
            The regions of this alpha shape are the ROIs, which are fed into the \emph{classificator}.
        }
    \subsection{Bounding box}\label{subsection:bounding_box}
        \par{
            The bounding box of a ROI can be easily calculated considering the extremal coordinates of its pixels.
        }
        \par{
            Let \texttt{pixels} be the $M \times 2$ matrix of the coordinates of the pixels within the ROI, with $M$ the number of pixels. Then the bounding box is: 
        }
        \par{
            \begin{BVerbatim}

                 _         _         
                | minX minY |
bounding_box =  | maxX maxY |
                 -         - 
            \end{BVerbatim}
        }
        \par{
            Where:
        }
        \par{
            \begin{BVerbatim} 

        minX = min(pixels(:,1))
        maxX = max(pixels(:,1))
        minY = min(pixels(:,2))
        maxY = max(pixels(:,2))
   
            \end{BVerbatim}
        }
        \par{
            As a first approximation, the implementation of the detector was done to output the bounding boxes instead of the alpha shape. Therefore, the $X$ set in \emph{Section \ref{subsection:segmentation}} is characterized by all the pixels inside the bounding box of the alpha shape regions.
        }
