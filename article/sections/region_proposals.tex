\section{Detector}\label{section:region_proposals}
    \par{
        The second stage of the proposed architecture is a \emph{detector} for region proposals, which are then fed into the \emph{classificator} for classification, which is described in \ref{section:mc-cnn}.
    }
    \par{
        The whole system relies on the \emph{detector} to spot one or more region of interest (ROI), which are the plausible candidates to be defective regions.
    }
    \par{
        To extract them, firstly an edge detector is used (\ref{subsection:contour_detection}). Its output is a binary matrix describing the edges found. The alpha shape of this matrix is then used to segmentate ROIs (\ref{subsection:segmentation}). Finally, the bounding box of the regions can be easily calculated (\ref{subsection:bounding_box}).
    }
    \subsection{Edge detection}\label{subsection:contour_detection}
        \par{
            The first step towards segmentation consist of the detection of edges inside the image, performed by the Kovesi algorithm and a hysteretic edge detector.
        }
        \par{
            The Kovesi algorithm \cite{mit:kovesiphase, googlescholar:kovesiphase} is a  \emph{phase congruency}-based edge detector. The main idea behind these types of detectors is that a edge appears where the local frequency components of the image are in phase (as shown in figure \ref{fig:phase-congruency}). There exist several metrics to evaluate the entity of phase congruency in a image. Some approaches are based on the Fourier analysis and a measure of local energy \cite{researchgate:phase}. Conversely, the Kovesi algorithm proposes an alternative method based on wavelets, which has the advantage of being dimensionless.
        }
    	\par{
    		The wavelets employed are the log-Gabor ones (see figure \ref{fig:gabor}), which at the $n=0$ scale have general expression:
    		\begin{equation*}
	    		G_0(\lambda, u; \rho, \theta) = e^{-\frac{(\log\rho/\rho_0)^2}{2(\log\kappa/\rho_0)^2}} e^{-\frac{(\theta-\theta_0)^2}{2\sigma^2}} e^{i\frac{2\pi}{\lambda} (u_x x + u_y y)}
    		\end{equation*}
    		where $(\rho,\lambda)$ and $(x,y)$ are respectively the spherical and cartesian coordinates of the points in the domain, $\lambda$ the wavelength and $u$ the direction of the envelope. The other parameters $(\rho_0, \theta_0)$ control the position of the centre of the envelope, whereas $\kappa, \sigma$ its shape.
	    }
		\par{
			Let consider first the setting with a single direction $u$. Given a image, for each pixel $q$ a square local window $W(q)$ of the image centered on $q$ is considered. Then, $W(q)$ is convolved with each one of the log-Gabor wavelets at the different scales $n = 0 \dots N-1$ obtaining a complex number
	    	\begin{equation*}
	    		z_{n} (q) = G_{n} * W(q)
	    	\end{equation*}
	    	then, by writing $z_{n} (q) = r_{n} (q) e^{i \alpha_{n} (q)}$ we can measure the phase congruency in correspondence of $q$ with:
            \begin{equation*}
	            \mathcal{P} (q) = \frac{\max(0,\lvert \sum_{n} z_{n} (q) \rvert - T)}{\sum_{n} r_{n} (q) + \varepsilon}
            \end{equation*}
            where $T$ is a constant which takes into account the effect of noise and $\varepsilon$ is a small value to address numerical problems that arise when the $r_n$ values are very small. A visualization of this metric can be found in figure \ref{fig:phase-congruency-metric}.
        }
	    \par{
	    	The size $(2k+1)\times(2k+1)$ of the local window $I(q)$ is taken such that $2k+1$ is at least $3$ times the wavelength $\lambda$.
		}
        \par{
        	In the general case the algorithm uses different orientations, identified by the solutions of $\sqrt[U]{i}$. The overall phase congruency metrics is then obtained by considering all the $r_{n,u}(q)$ and $\alpha_{n,u}(q)$. Moreover, considerations concerning frequency and phase spread allow to obtain a slightly different but more effective metrics for phase congruency. A discussion of these details can be found in \cite{mit:kovesiphase}.
        }
        \par{
        	The given $\mathcal{P}$ lies in the $[0,1]$ interval. In our study we have observed that performing a \emph{min-max normalization} of each single image
        	PARAGRAFETTO DA COMMENTARE DOPO AVER VISTO I RISULTATI
        	\begin{equation*}
        	\hat{\mathcal{P}}(q) = 255 \cdot \frac{\mathcal{P}(q)-\min_q\mathcal{P}(q)}{\max_q\mathcal{P}(q)-\min_q\mathcal{P}(q)}
        	\end{equation*}
        }
        \par{
        	The Kovesi algorithm is based on several parameters that need to be tuned to obtain an efficient edge detector. In our study we have take into account only the \emph{number of scales} $N$, the \emph{number of orientations} $U$, the wavelength $\lambda$ and the \emph{scaling factor} $s$ of wavelets. Their tuning has been performed using Bayesian optimization, as described in section \ref{subsection:bounding_box}.
        }
	    \begin{figure}
		    \centering
		    \includegraphics[width=\linewidth]{graphics/architecture/phasecong}
		    \caption{Visualization of the phase congruency concept for a 1D signal. The sum (blue line) of the frequency components (red and orange lines) gradually approaches a discontinuity where the components are in phase.}
		    \label{fig:phase-congruency}
		\end{figure}
		\begin{figure}
			\centering
			\includegraphics[width=\linewidth]{graphics/architecture/gabor}
			\caption{Examples of Gabor wavelets with different directions and scales.}
			\label{fig:gabor}
		\end{figure}
	    \begin{figure}
	    	\centering
	    	\includegraphics[width=\linewidth]{graphics/architecture/phasecong_metric}
	    	\caption{Phase congruency metric.}
	    	\label{fig:phase-congruency-metric}
	    \end{figure}
        \par{
            The output of the Kovesi algorithm cannot be used directly for segmentation because is tipically susceptible to isolated edge-like patterns that arise COMPLETARE. Hence, a hysteretic edge follower has been used to remove such patterns.
        }
        \par{
        	In this step, the pixels with $\mathcal{P}(p) > T_{low}$
        	are trace and marked as being edge pixels. Such traces are initialized by locations $q$ with $\mathcal{P}(p) > T_{high}$.
        }
    	\par{
            In details, the algorithm in the following:
        }
		\begin{enumerate}
			\item Scan the image and find a not yet marked pixel $q$ with $\hat{\mathcal{P}}(q) \ge T_{high}$ and mark it as edge.
			\item Scan the $8$-neighbourhood $\Omega(q)$ of $q$, for each not-yet marked $p \in \Omega(q)$, mark it as edge if $\hat{\mathcal{P}}(p) \ge T_{low}$.
			\item Repeat from step 1) until there are still not marked pixels.
		\end{enumerate}
		\par{
			The output is a binary matrix with marked positions of edge pixels, ready for the segmentation procedure.
		}
        \par{
            The hysteretic parameters \emph{low-threshold} $T_{low}$ and \emph{high-threshold} $T_{high}$ have been tuned through Bayesian optimization \cite{arXiv:2012arXiv1206.2944S,arXiv:2018arXiv180702811F, matlab:bayesian-opt}, together with the parameteres in \ref{subsection:segmentation} and with the parameters of the Kovesi algorithm.
        }
    	\par{
    		The latter techniques has been implemented with the P. Kovesi \texttt{MATLAB} library, available at \cite{kovesilibrary}.
    	}
    	\begin{figure}
    		% \includegraphics[width=\linewidth]{graphics/architecture/detector_ex_original}
    		\vskip .05cm
    		% \includegraphics[width=\linewidth]{graphics/architecture/detector_ex_kovesi}
    		\vskip .05cm
    		% \includegraphics[width=\linewidth]{graphics/architecture/detector_ex_hysteresis}
    		\vskip .05cm
    		\caption{Edge-detector results on a sample image. DA FARE FACENDO NOTARE I PUNTI SPARSI TROVATI CHE VENGONO RIPULITI DALL'ISTERESI}
    		\label{fig:edge-detector-example}
    	\end{figure}
    \subsection{Image Segmentation}\label{subsection:segmentation}
        \par{
            Given the plausible edges found by the previous step, the image segmentation is done banking on alpha shapes \cite{springer:10.1007/11907350_46}.
        }
        \par{
            The Delaunay triangulation $\mathcal{D}$ od a set of point $\mathcal{S}$ is the subset of all triangles $T = \left\{\left(a, b, c\right) \subset \mathcal{S}^3, a \neq b, b \neq c, a \neq c \right\}$ such that $t \in T, x \in \mathcal{S} \Rightarrow x \not\in \mathcal{C}\left(t\right)$, where $\mathcal{C}\left(t\right)$ is the circumcircle of $t$.
        }
        \par{
            The union of cells $c \in \mathcal{D}$ is called polytope of $\mathcal{D}$. 
            \begin{equation*}
                \mathcal{D}_\alpha = \left\{t \in T \colon r\left(\mathcal{C}\left(t\right)\right) < \alpha\right\}
            \end{equation*}
            Where $r\left(\mathcal{C}\left(t\right)\right)$ is the radius of the circumcircle of $t$. The polytope of $\mathcal{D}_\alpha$ is called \emph{alpha-shape}.
        }
        \begin{figure}
            \centering
            \includegraphics[width=\linewidth]{graphics/architecture/detector-points}
            \includegraphics[width=\linewidth]{graphics/architecture/detector-a-shape}
            \includegraphics[width=\linewidth]{graphics/architecture/detector-a-shape-better-radius}
            \caption{Alpha shape with different alphas of a set of points.}\label{fig:example-alpha-shape}
        \end{figure}
        \begin{figure}
            \centering
            \includegraphics[width=\linewidth]{graphics/architecture/detector-convhull}
            \caption{Convex hull of a set of points.}\label{fig:example-convex-hull}
        \end{figure}
        \par{
            As an example, in figure \ref{fig:example-alpha-shape} are compared the alpha-shapes with different $\alpha$ values of a set of points. In figure \ref{fig:example-convex-hull} is shown the convex-hull of the same set of points. The choice of alpha shapes for the given task is clear.
        }
        \par{
            However, in order to obtain topologically correct image segmentation, three parameters need to be properly choosen \cite{springer:10.1007/11907350_46}. These are the \emph{alpha-radius}, the \emph{hole-thresholding} and the \emph{region-thresholding} \cite{matlab:alpha-shape}.
        }
        \par{
            The first is the value of $\alpha$, the second is the maximum area of interior holes that is filled and the third is the largest area that is suppressed (ignored).
        }
        \par{
            Observe that the latter is useful to soothe the effects of noisy edge detections.
        }
        \par{
            However, tuning them manually is quixotic, hence they are choosen through Bayesian optimization.
        }
        \par{
            The segmentation step outputs a set of pixels, which can be compared with the ideal segmentation, i.e. only the pixels within some defective region.
        }
        \par{
            Therefore, the goodness of fit of the set of proposed pixels $\left(X\right)$ to the ideal pixels $\left(Y\right)$ can be measured as:
            \begin{equation*}
                \chi\left(X, Y\right) = \frac{2 \lvert X \cap Y \rvert}{\lvert X \rvert + \lvert Y \rvert}
            \end{equation*}
        }
        \par{
            Hence, the loss function is:
            \begin{equation*}
                \mathcal{L}\left(X, Y\right) = 1 - \chi\left(X, Y\right)
            \end{equation*}
        }
        \par{
            The acquisition function used is \emph{expected-improvement-plus} \cite{matlab:acquisition}.
        }
        \par{
            As a final consideration, using alpha shape lessen the detrimental effect of the noise in edge detection. Indeed, outliers are suppressed by the hole threshold and region threshold parameteres.
        }
        \begin{figure}
            \caption{Bayesian optimization on image segmentation.}\label{fig:image-segmentation-optimization}
        \end{figure}
        \par{
            In figure \ref{fig:image-segmentation-optimization} ** DESCRIVERE OUTPUT BAYESIAN **
        }
        \par{
            The regions of this alpha shape are the ROIs, which are fed into the \emph{classificator}.
        }
    \subsection{Bounding box}\label{subsection:bounding_box}
        \par{
            The bounding box of a ROI can be easily calculated considering the extremal coordinates of its pixels.
        }
        \par{
            Let \texttt{pixels} be the $M \times 2$ matrix of the coordinates of the pixels within the ROI, with $M$ the number of pixels. Then the bounding box is: 
        }
        \par{
            \begin{BVerbatim}

                 _         _         
                | minX minY |
bounding_box =  | maxX maxY |
                 -         - 
            \end{BVerbatim}
        }
        \par{
            Where:
        }
        \par{
            \begin{BVerbatim} 

        minX = min(pixels(:,1))
        maxX = max(pixels(:,1))
        minY = min(pixels(:,2))
        maxY = max(pixels(:,2))
   
            \end{BVerbatim}
        }