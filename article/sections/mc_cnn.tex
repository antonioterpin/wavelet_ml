\section{Classificator}\label{section:mc-cnn}
    \par{
        The ROIs are then fed into the second part of the proposed architecture, the \emph{classificator}, and properly classified as flawless or flawed; in the latter, they are assigned a defect class.
    }
    \begin{figure}
        \centering
        \begin{tikzpicture}
            % image
            \node[circle, draw] (input) at (0,0) {I};
    
            % preprocessed image
            \node[rectangle, draw] (p1) at ($(input) + (1.5,2)$) {P};
            \node[rectangle, draw] (p2) at ($(input) + (1.5,.5)$) {P};
            \node (p3) at ($(input) + (1.5,-.5)$) {\vdots};
            \node[rectangle, draw] (p4) at ($(input) + (1.5,-2)$) {P};
    
            % image to preprocessed image
            \draw[->] ($(input) + (0.5, 0)$) -- ($(p1) + (-0.3, 0)$);
            \draw[->] ($(input) + (0.5, 0)$) -- ($(p2) + (-0.3, 0)$);
            \draw[->] ($(input) + (0.5, 0)$) -- ($(p4) + (-0.3, 0)$);
    
            % cnn
            \node[rounded rectangle, draw, minimum width=2.5cm, minimum height=1cm] (cnn1) at ($(p1) + (2,0)$) {CNN};
            \node[rounded rectangle, draw, minimum width=2.5cm, minimum height=1cm] (cnn2) at ($(p2) + (2,0)$) {CNN};
            \node[minimum width=2.5cm, minimum height=1cm] (cnn3) at ($(p3) + (2,0)$) {\vdots};
            \node[rounded rectangle, draw, minimum width=2.5cm, minimum height=1cm] (cnn4) at ($(p4) + (2,0)$) {CNN};
    
            % preprocessed to cnn
            \draw[->] ($(p1) + (0.5, 0)$) -- ($(cnn1) + (-1.2, 0)$);
            \draw[->] ($(p2) + (0.5, 0)$) -- ($(cnn2) + (-1.2, 0)$);
            \draw[->] ($(p4) + (0.5, 0)$) -- ($(cnn4) + (-1.2, 0)$);
    
            % classifier
            \node[rounded rectangle, draw] (classifier) at ($(cnn3) + (2.5,0.5)$) {NN};
    
            % cnn to classifier
            \draw[->] ($(cnn1) + (1.3, 0)$) -- ($(classifier) + (-.5, .2)$);
            \draw[->] ($(cnn2) + (1.3, 0)$) -- ($(classifier) + (-.5, 0)$);
            \draw[->] ($(cnn4) + (1.3, 0)$) -- ($(classifier) + (-.5, -.2)$);
    
            % output
            \node[circle, draw] (output) at ($(classifier) + (1.3,0)$) {O};
    
            % classifier to output
            \draw[->] ($(classifier) + (.5, 0)$) -- ($(output) + (-.45, 0)$);
    
        \end{tikzpicture}
        \caption{General structure of a MC-CNN}\label{fig:mc-cnn}
    \end{figure}
    \par{
        The \emph{classificator} is structured as a MC-CNN, which in general has a structure similar to the one in figure \ref{fig:mc-cnn}. 
    }
    \par{
        Firstly, the input image I is eventually preprocessed to extract $n$ column input P.
    }
    \par{
        Secondly, these P are fed into different CNNs in parallel, therefore independently. 
    }
    \par{
        Finally, the output of the MC-CNN columns is combined through a final classificator, e.g. a neural network (NN), to produce the appropriate output.
    }
    \par{
        The choice of using a MC-CNN is due to several reasons, beyond the proved effectiveness described in \cite{ieee:6248110}.
    }
    \par{
        Primarily, the training of a MC-CNN is highly parallelizable, indeed the different columns can learn separately one from another, once their correspective input is prepared.
    }
    \par{
        Moreover, it is possible to merge both local and global information in a far easier way then using a traditional, single-column, CNN. Indeed, instead of focusing only on a rectangular area, which brings only the local information about the plausible defect, with a MC-CNN it is immediate to add another column concerning with the whole image.
    }
    \par{
        This is the main point in favour of MC-CNN, since the class of a defect may be inferred using global patterns, such as the number of similar area. Imagine, for example, an error burst on the surface. Although traditional single-column CNNs may consider directly the input to the global column, this would face problems regarding the presence of multiple defects classes on the same surface. Therefore, a MC-CNN approach with some columns concerning local information and other focusing on global patterns is heuristically better.
    }
    \par{
        However, in \ref{section:further-work} another approach to combine such information through a CNN is described. Although possible, is patently more convoluted then the MC-CNN approach. It would still be interesting to compare them in order to characterize the effectiveness. 
    }
    \par{
        Observe that the output of global column must be calculated only once per each image, since it is constant throughtout the single surface, hence both the training and the predicting process can be lighten.
    }
    \par{
        Finally, as an incidental outcome, it is possible to further study the amount of contribution of the different columns in accurately determining the defective class, if any, of the considered area. This considerations are reported in \ref{section:results}.
    }
    \par{
        The proposed MC-CNN has three columns, namely a \emph{shape}, a \emph{local} and a \emph{global} column.
    }
    \par{
        A final consideration about the architecture training has to be done in order to comprehend the upper bound reported in \ref{section:results}. Indeed, the \emph{classificator} has been implemented before the \emph{detector}. In fact, although the former relies on the latter for the ROIs and their relative features (described in \ref{section:shape-column}, \ref{section:local-column} and \ref{section:global-column}), it has been preempting supposed to have an ideal \emph{detector}, i.e. one which proposes the optimal ROIs.
    }
    \par{
        This effort-outcome oriented approach has been done for two main reasons.
    }
    \par{
        Firstly, this approach highlight the upper bound reachable with the whole architecture.
    }
    \par{
        Secondly, dividing the \emph{detector} outcome from the \emph{classificator} input during the training allows to export the trained MC-CNN and to use it within the challenger architecture, explained in \ref{section:challenger}. This specifies the effectiveness of the \emph{detector} proposed.
    }
    \subsection{Shape column}\label{section:shape-column}
        \par{
            The \emph{shape column} is concerned to learn from the shape of the proposed region. This is fed into the CNN as a binary matrix, in which ones represent points in the border of the area.
        }
        \begin{figure}
            \centering
            \includegraphics[width=\linewidth]{graphics/architecture/mc-cnn-shape}
            \caption{Shape column input.}\label{fig:mc-cnn:shape-input}
        \end{figure}
        \par{
            An example of this binary images is given in figure \ref{fig:mc-cnn:shape-input}. The shape is centered in a $1600\times 256$ black image. Indeed, the size of the input is set to the largest area that could be found, i.e. a defect spanning over the entire surface. The shape is centered to ensure that the classificator is translation independent. 
        }
        \par{
            In order to provide also negative examples, i.e. flawless areas proposed by the \emph{detector}, while training the \emph{classificator} with ideal input, it is needed to generate those.
        }
        \par{
            *** TODO DESCRIBE FAKE ELEMENTS GENERATION ***
        }
        \begin{figure}
            \centering
            % \includegraphics[]{}
            \caption{Shape column CNN layers}\label{fig:mc-cnn:shape-structure}
        \end{figure}
        \par{
            The layers of this CNN are shown in \ref{fig:mc-cnn:shape-structure}. *** ... explanation, dimensioning, type of layers .... Stats on defects shapes.... ***
        }
        \par{
            The output layer is a $n + 1$ vector, where $n$ is the number of defect classes. Each entry of this vector describe the confidence of the network in considering the input shape as flawless or related to one of the $n$ defect classes.
        }
    \subsection{Local column}\label{section:local-column}
        \par{
            The \emph{local column} is thought to consider luminance levels around the border of the defect, to learn from the local context wheter a region proposal is defective or not, and eventually its class.
        }
        \begin{figure}
            \centering
            \includegraphics[width=\linewidth]{graphics/architecture/mc-cnn-local}
            \caption{Local column input.}\label{fig:mc-cnn:local-input}
        \end{figure}
        \par{
            Therefore, the column is fed with the grey scale portion of the image in which the considered region is. As an example, in figure \ref{fig:mc-cnn:local-input} is illustrated a plausible input to the \emph{local column}.
        }
        \par{
            This grey scale portion is generated from the shape of the region and the original image.
        }
        \par{
            Firstly, the bounding box of the shape is calculated. Secondly, the original image outside the bounding box is discarded. Finally, the cropped image is centered in a black $1600\times 256$ picture. The reasons behind the centering and the dimensioning of the input are the same described in \ref{section:shape-column}.
        }
        \begin{figure}
            \centering
            % \includegraphics[]{}
            \caption{Local column CNN layers}\label{fig:mc-cnn:local-structure}
        \end{figure}
        \par{
            The layers of this CNN are shown in \ref{fig:mc-cnn:local-structure}. *** ... explanation .... Stats on defects shapes.... ***
        }
        \par{
            The output layer is analogous to the one in \ref{section:shape-column}.
        }
    \subsection{Global column}\label{section:global-column}
        \begin{figure}
            \centering
            \includegraphics[width=\linewidth]{graphics/architecture/mc-cnn-global}
            \caption{Global column input.}\label{fig:mc-cnn:global-input}
        \end{figure}
        \par{
            The \emph{global column} is concerned in detecting global patterns, like zipper cracks. Hence, it is fed with the whole image. An example of input is shown in figure \ref{fig:mc-cnn:global-input}. The importance of this column is clear from the observations made in \ref{subsection:defects}. Indeed, when two different classes are locally equal, the global column is determinant to correctly classify the defects.
        }
        \begin{figure}
            \centering
            % \includegraphics[]{}
            \caption{Global column CNN layers}\label{fig:mc-cnn:global-structure}
        \end{figure}
        \par{
            *** structure, explanation, output ***\\
            *** MAYBE OUTPUT AS MULTIPLE COMBINATIONS CLASSES? *** \\
            *** DESCRIBE STRUCTURE, RATIONALE BEHIND DIMENSIONING, USE DEFECT STATS ***
        }
    \subsection{Final classifier}
        \par{
            The outcomes of the different columns of a MC-CNN are then combined to obtain the final output. In the proposed architecture, this combination is done through a neural network, since a manual tuning of such combination would be ineffective.
        }
        \begin{figure}
            \centering
            \begin{tikzpicture}
                % input layer
                \foreach \i in {0,...,11} % TODO fix
                    \node[circle, draw, minimum height=1, minimum width=1,fill=blue] (input \i) at (0,-\i*0.5) {};

                % hidden layer
                \foreach \i in {0,...,7} % TODO fix
                    \node[circle, draw, minimum height=1, minimum width=1,fill=orange] (hidden \i) at ($(input 2) + (2,-\i*0.5)$) {};

                % from input to hidden layer
                \foreach \i in {0,...,11}
                    \foreach \j in {0,...,7}
                        \draw[->] ($(input \i) + (.2,0)$) -- ($(hidden \j) + (-.2,0)$);

                % output layer
                \foreach \i in {0,...,4} % TODO fix
                    \node[circle, draw, minimum height=1, minimum width=1,fill=yellow] (output \i) at ($(hidden 1) + (2,-\i*0.5)$) {};

                % from hidden to output layer
                \foreach \i in {0,...,7}
                    \foreach \j in {0,...,4}
                        \draw[->] ($(hidden \i) + (.2,0)$) -- ($(output \j) + (-.2,0)$);

                % from output to softmax layer
                \foreach \i in {0,...,4}
                    \draw[->] ($(output \i) + (.2,0)$) -- ($(output \i) + (2,0)$);

                % softmax layer
                \node[rounded rectangle, fill=white, minimum width=3cm,draw,rotate=-90] (softmax) at ($(output 2) + (1,0)$) {Softmax};

                % legend
                \node[rectangle, draw, fill=yellow, minimum width=1, minimum height=1] (output label color) at ($(output 0) + (0,1)$) {};
                \node[anchor=west] (output label) at ($(output label color) + (.2,0)$) {Output layer};

                \node[rectangle, draw, fill=orange, minimum width=1, minimum height=1] (hidden label color) at ($(output label color) + (0,.5)$) {};
                \node[anchor=west] (hidden label) at ($(hidden label color) + (.2,0)$) {Hidden layer};

                \node[rectangle, draw, fill=blue, minimum width=1, minimum height=1] (input label color) at ($(hidden label color) + (0,.5)$) {};
                \node[anchor=west] (input label) at ($(input label color) + (.2,0)$) {Input layer};

                \node[anchor=west] (legend label) at ($(input label color) + (-.25,.5)$) {\underline{Legend}};
            \end{tikzpicture}
            \caption{Final classifier structure.}\label{fig:mc-cnn:final-classifier-structure}
        \end{figure}
        \par{
            In figure \ref{fig:mc-cnn:final-classifier-structure} the structure of the last layer of the architecture is shown.
        }
        \par{
            The first layer is constrained to the output size of the three columns, i.e. *** TODO COMPLETARE... *** Then there is an hidden layers with $7$ activation units, and finally the output layer with $5$ neurons. The output is passed through a softmax layer, hence the final output describe the confidence per each class.
        }
        \par{
            Observe that bias units have not been included in any layer.
        }
        \par{
            ** DISPLAY WEIGHTS, infer what matters most to determine output **
        }
        \par{
            The results of this architecture are shown in \ref{section:results}.
        }
