\subsection{Optimization}
\begin{frame}
    \frametitle{Optimization}
    \onslide <1-> {
        \begin{block}{Bayesian optimization}
            Bayesian optimization aims to solve an optimization problem $\max\limits_{x\in A}f\left(x\right)$ when:
            \begin{itemize}
                \item $A \subset \mathbb{R}^d$ with $d$ not too large.
                \item Easy to asses $A$ membership.
                \item $f$ can be modeled using \emph{Gaussian process regression}.
                \item $f$ is a \emph{black box}.
            \end{itemize}
        \end{block}
    }
    \onslide <2-> {
        \begin{exampleblock}{Loss function}
            \begin{equation}
                J\left(\alpha\right) = \frac{2\lvert X \cap Y \rvert}{\lvert X \rvert + \lvert Y \rvert} = -f(x)
            \end{equation}
        \end{exampleblock}
    }
\end{frame}

\begin{frame}
    \frametitle{Optimization}
    \vskip -0.5cm
    \begin{block}{Bayesian optimization}
        Firstly a collection of points $x_1, \ldots, x_k \in \mathbb{R}^d$ is considered. Suppose $f$ can be modeled as:
        \begin{equation*}
            f\left(x_{1:n}\right) \sim \mathcal{N}\left(\mu\left(x_{1:n}\right), \Sigma\left(x_{1:n}, x_{1:n}\right)\right)
        \end{equation*}
        Then we can infere the probability distribution of $f\left(x_{n+1}\right)$:
        \begin{equation}
            f\left(x_{n+1}\right) \mid f\left(x_{1:n}\right) \sim \mathcal{N}\left(\mu_{n+1}, \Sigma_{n+1}\right)
        \end{equation}
        \begin{equation*}
            \mu_{n+1} = \Sigma\left(x_{n+1}, x_{1:n}\right)\Sigma\left(x_{1:n}, x_{1:n}\right)^{-1}\left(f\left(x_{1:n}\right) - \mu\left(x_{1:n}\right)\right) + \mu\left(x_{n}\right)
        \end{equation*}
        \begin{equation*}
            \Sigma_n = \Sigma\left(x_{n+1}, x_{n+1}\right) - \Sigma\left(x_{n+1}, x_{1:n}\right)\Sigma\left(x_{1:n}, x_{1:n}\right)^{-1}\Sigma\left(x_{1:n}, x_{n+1}\right)
        \end{equation*}
    \end{block}
\end{frame}

\begin{frame}
    \frametitle{Optimization}
    \begin{exampleblock}{Acquisition function}
        Therefore, it is possible to consider an \emph{acquisition function}, i.e. a function that given the previous $x_1, \ldots, x_n$ values determines the best choice of $x_{n+1}$:
        \begin{equation}
            a \colon \left[x_1 \ldots x_n\right] \rightarrow x_{n+1} \colon \mathcal{P}\left[f(x_{n+1}) = \max\limits_{x \in A} f\left(x\right)\right] \text{is max}
        \end{equation}
    \end{exampleblock}
\end{frame}